#크롤링
install.packages("rvest")
install.packages("R6")
install.packages("stringr")
library(rvest)
library(R6)
library(stringr)

boxoffice <- read.csv("C:/Users/default.default-PC/Desktop/데이터시각화/박스오피스.csv")

page <- boxoffice$페이지
start <- boxoffice$start
end <- boxoffice$end
name <- boxoffice$영화명

##네이버 페이지 주소##
main_url = page[1]

reply_list = character()
star_list = numeric()
date_list = character()

for(page_url in start[1]:end[1]){
  
  url = paste(main_url, page_url, sep="")
  content = read_html(url)
  
  node_1 = html_nodes(content, ".score_reple p")
  node_2 = html_nodes(content, ".score_result .star_score em")
  node_3 = html_nodes(content, ".score_reple em:nth-child(2)")
  
  reply = html_text(node_1)
  star = html_text(node_2)
  date = html_text(node_3)
  date = as.Date(gsub("\\.","-", date))
  
  reply_list = append(reply_list, reply)
  star_list = append(star_list, star)
  date_list = append(date_list, date)
}

df = data.frame(reply_list, star_list, date_list)
colnames(df) = c("reply","rank","date")

write.csv(df, "aladin.csv", row.names = FALSE)

#감성분석
install.packages("plyr")
install.packages("stringr")
install.packages("NLP")
install.packages("tm")
install.packages("data.table")
install.packages("stringr")
install.packages("wordcloud")
install.packages("RPMG")



library(plyr)
library(stringr)
library(NLP)
library(tm)
library(data.table)
library(stringr)
library(wordcloud)
library(RPMG)


setwd("C:/Users/default.default-PC/Desktop/컴퓨터")

r <- c(16:20,26:30)
emotion <- data.frame()

for(i in r) {
  data = read.csv(paste("C:/Users/default .default-PC/Desktop/컴퓨터/영화/movie",i,'.csv',sep=''),stringsAsFactors = F)

  #dictionary
  posDic = readLines("C:/Users/default.default-PC/Desktop/컴퓨터/positive-words.txt")
  negDic = readLines("C:/Users/default.default-PC/Desktop/컴퓨터/negative-words.txt")

  #processing
  sentimental = function(sentences, posDic, negDic){
  
  scores = laply(sentences, function(sentence, posDic, negDic) {
    
    sentence = gsub('[[:punct:]]', '', sentence) # 문장부호 제거
    sentence = gsub('[[:cntrl:]]', '', sentence) # 특수문자 제거
    sentence = gsub('\\d+', '', sentence)        # 숫자 제거
    
    sentence = tolower(sentence)                 # 모두 소문자로 변경(단어가 모두 소문자 임)
    
    word.list = str_split(sentence, '\\s+')      # 공백 기준으로 단어 생성 > \\s+ : 공백 정규식, +(1개 이상) 
    words = unlist(word.list)                    # unlist() : list를 vector 객체로 구조변경
    
    
    pos.matches = match(words, posDic)           # words의 단어를 posDic에서 matching
    neg.matches = match(words, negDic)
    
    pos.matches = !is.na(pos.matches)            # NA 제거, 위치(숫자)만 추출
    neg.matches = !is.na(neg.matches)
    
    score = sum(pos.matches) - sum(neg.matches)  # 긍정 - 부정
    return(score)
  }, posDic, negDic)
  
  scores.df = data.frame(score=scores, text=sentences)
  return(scores.df)
  }

  result=sentimental(data[,1], posDic, negDic)

  result$remark[result$score >=1] = "긍정"
  result$remark[result$score ==0] = "중립"
  result$remark[result$score < 0] = "부정"

  sentiment_result= table(result$remark)

  emotion[i,1] <- sentiment_result[1]
  emotion[i,2] <- sentiment_result[3]
  emotion[i,3] <- sentiment_result[2]
}


write.csv(emotion,"2017emotion.csv",row.names=FALSE)

#기계학습
#########################################################트리트리모형
#의사결정나무 패키지 3개존재(tree,rpart,party)
#데이터준비-의사결정나무만들기-가지치기-예측 및 모델평가단계

#A.데이터 준비
df<-read.csv("data.csv")

#첫번째 tree패키지 이용
#caret패키지를 사용해서 데이터를 trani셋과 test셋으로 구분.(트리모형의 성능향상을 위해)
#70%는 train을 위해 30%는 test를 위해 준비.
install.packages("caret")
library(caret)

train<-df[1:30,]
test <- df[31:40,]

#B.의사결정 나무 형성
#train데이터 셋을 이용해서 의사결정나무 만들기.
install.packages("tree")
library(tree)
treemod<-tree(흥행수준~. , data=train)
dev.new()
plot(treemod)
text(treemod)


#C.가지치기(PRUNING)
#k-fold cross-validation을 사용해서  train셋을 여러번 쪼개서 테스트함.
#분산이 가장 낮은 가지수를 선택하면 됨.
#tree패키지에서 제공하는 cv.tree함수를 사용하면 간단하게 확인가능함.
cv.trees<-cv.tree(treemod, FUN=prune.tree ) 
##수정해봐야함. for classification decision tree
##FUN=prune.misclass 조건 다른거 있는지 확인해서 해보기
dev.new()
plot(cv.trees)



#CV그래프를 보니 13개의 가지의 트리모형이 가장 분산이 낮다.
#PRUNING함
prune.trees <- prune.tree(treemod, best=???)  # for regression decision tree, use prune.tree function
dev.new()
plot(prune.trees)
text(prune.trees, pretty=0)



#D.예측하기&모델 평가
install.packages("e1071")
library(e1071)
####################################################treepred오류&confusionMatrix오류
str(prune.trees)
treepred <- predict(prune.trees, test, type='class')
confusionMatrix(treepred, test$흥행수준)
