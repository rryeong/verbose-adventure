#크롤링

library(rvest)
library(R6)
library(stringr)

boxoffice <- read.csv("C:/Users/default.default-PC/Desktop/데이터시각화/박스오피스.csv")

page <- boxoffice$페이지
start <- boxoffice$start
end <- boxoffice$end
name <- boxoffice$영화명

##네이버 페이지 주소##
main_url = page[1]

reply_list = character()
star_list = numeric()
date_list = character()

for(page_url in start[1]:end[1]){
  
  url = paste(main_url, page_url, sep="")
  content = read_html(url)
  
  node_1 = html_nodes(content, ".score_reple p")
  node_2 = html_nodes(content, ".score_result .star_score em")
  node_3 = html_nodes(content, ".score_reple em:nth-child(2)")
  
  reply = html_text(node_1)
  star = html_text(node_2)
  date = html_text(node_3)
  date = as.Date(gsub("\\.","-", date))
  
  reply_list = append(reply_list, reply)
  star_list = append(star_list, star)
  date_list = append(date_list, date)
}

df = data.frame(reply_list, star_list, date_list)
colnames(df) = c("reply","rank","date")

write.csv(df, "aladin.csv", row.names = FALSE)


#감성분석

library(plyr)
library(stringr)
library(NLP)
library(tm)
library(data.table)
library(stringr)
library(wordcloud)
library(RPMG)


setwd("C:/Users/default.default-PC/Desktop/컴퓨터")

r <- c(16:20,26:30)
emotion <- data.frame()

for(i in r) {
  data = read.csv(paste("C:/Users/default .default-PC/Desktop/컴퓨터/영화/movie",i,'.csv',sep=''),stringsAsFactors = F)

  #dictionary
  posDic = readLines("C:/Users/default.default-PC/Desktop/컴퓨터/positive-words.txt")
  negDic = readLines("C:/Users/default.default-PC/Desktop/컴퓨터/negative-words.txt")

  #processing
  sentimental = function(sentences, posDic, negDic){
  
  scores = laply(sentences, function(sentence, posDic, negDic) {
    
    sentence = gsub('[[:punct:]]', '', sentence) # 문장부호 제거
    sentence = gsub('[[:cntrl:]]', '', sentence) # 특수문자 제거
    sentence = gsub('\\d+', '', sentence)        # 숫자 제거
    
    sentence = tolower(sentence)                 # 모두 소문자로 변경(단어가 모두 소문자 임)
    
    word.list = str_split(sentence, '\\s+')      # 공백 기준으로 단어 생성 > \\s+ : 공백 정규식, +(1개 이상) 
    words = unlist(word.list)                    # unlist() : list를 vector 객체로 구조변경
    
    
    pos.matches = match(words, posDic)           # words의 단어를 posDic에서 matching
    neg.matches = match(words, negDic)
    
    pos.matches = !is.na(pos.matches)            # NA 제거, 위치(숫자)만 추출
    neg.matches = !is.na(neg.matches)
    
    score = sum(pos.matches) - sum(neg.matches)  # 긍정 - 부정
    return(score)
  }, posDic, negDic)


#마이닝


library(plyr)
library(stringr)
library(NLP)
library(tm)
library(data.table)
library(stringr)
library(wordcloud)
library(RPMG)

data1 = read.csv("C:/Users/sjsj9/Desktop/세진이와 함께하는 행복한 텍스트마이닝/엑셀/영화/movie1.csv",stringsAsFactors = F)
data1=data1$reply[1:1000]
data2 = read.csv("C:/Users/sjsj9/Desktop/세진이와 함께하는 행복한 텍스트마이닝/엑셀/영화/movie16.csv",stringsAsFactors = F)
data2=data2$reply[1:1000]
data3 = read.csv("C:/Users/sjsj9/Desktop/세진이와 함께하는 행복한 텍스트마이닝/엑셀/영화/movie31.csv",stringsAsFactors = F)
data3=data3$reply[1:1000]


data=rbind(data1,data2,data3)


#processing
sentimental = function(sentence) {
        
        sentence = gsub('[[:punct:]]', '', sentence) # 문장부호 제거
        sentence = gsub('[[:cntrl:]]', '', sentence) # 특수문자 제거
        sentence = gsub('\\d+', '', sentence)        # 숫자 제거
        
        sentence = tolower(sentence)                 # 모두 소문자로 변경(단어가 모두 소문자 임)
        
        word.list = str_split(sentence, '\\s+')      # 공백 기준으로 단어 생성 > \\s+ : 공백 정규식, +(1개 이상) 
        words = unlist(word.list)                    # unlist() : list를 vector 객체로 구조변경
    
    return(words)
}

result=sentimental(data)

#wordcloud
wordcloud(result,min.freq = 3,max.words = 40,random.order = FALSE,col = colors())


#기계학습

setwd("C:/Users/default.default-PC/Desktop/데이터시각화")
df<-read.csv("C:/Users/default.default-PC/Desktop/데이터시각화/엑셀/박스오피스(최종수정).csv")
sdf<-df$관객수
sdf<-as.vector(sdf)

quantile(sdf)

sdf_0=1826912 #0%
sdf_25=2605355 #25%
sdf_50=4163710 #50%
sdf_75=7583174 #75%
sdf_100=16265494 #100%

sdf_025=df

sdf_quartile_1 = subset(df, subset=c(관객수 >= sdf_0 & 관객수 < sdf_25)) #1
sdf_quartile_2 = subset(df, subset=c(관객수 >= sdf_25 & 관객수 < sdf_50)) #2
sdf_quartile_3 = subset(df, subset=c(관객수 >= sdf_50 & 관객수 < sdf_75)) #3
sdf_quartile_4 = subset(df, subset=c(관객수>= sdf_75 & 관객수 <= sdf_100)) #4

#(아주나쁨,나쁨,좋음,아주좋음)
df<-read.csv("C:/Users/default.default-PC/Desktop/데이터시각화/엑셀/박스오피스(최종수정).csv")
colnames(df)
dt<-df[,c(1,5,6,9,11,15,16,17)]

library(MASS)
library(randomForest)
library(caret)

set.seed(10)
intrain<-createDataPartition(y=dt$흥행수준, p=0.7, list=FALSE) 
train<-dt[intrain, ] #70%
test<-dt[-intrain, ] #30%


rf.fit <- randomForest(흥행수준~.,data=train,mtry=4,ntree=200, importance=T)
test_x <- test[,c(-1)]
test_y <- test[,1]

y_pred =predict(rf.fit,test_x)

confusionMatrix(y_pred,test_y)
